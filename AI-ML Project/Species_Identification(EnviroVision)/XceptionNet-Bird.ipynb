{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207fb217-4c3c-42a7-bc96-3062272587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Optimized Code for Bird Classification\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress AVX warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Mitigate OpenMP conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation with Mixup and CutMix\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, alpha=0.4, cutmix_prob=0.5):\n",
    "        self.generator = generator\n",
    "        self.alpha = alpha\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generator)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, labels = self.generator[index]\n",
    "        \n",
    "        if np.random.rand() < self.cutmix_prob:\n",
    "            return self.cutmix(images, labels)\n",
    "        else:\n",
    "            return self.mixup(images, labels)\n",
    "    \n",
    "    def mixup(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_images = lam * images + (1 - lam) * shuffled_images\n",
    "        mixed_labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def cutmix(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.shape, lam)\n",
    "        images[:, bbx1:bbx2, bby1:bby2, :] = shuffled_images[:, bbx1:bbx2, bby1:bby2, :]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.shape[1] * images.shape[2]))\n",
    "        labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return images, labels\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W = size[1]\n",
    "        H = size[2]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "462ce40c-e971-4fd7-99a6-ea9174ea6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (UPDATE THESE TO YOUR LOCAL PATHS)\n",
    "train_path = 'D:/Dataset/Birds_CNN/Train'\n",
    "test_path = 'D:/Dataset/Birds_CNN/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c6bf77-7736-4371-a847-0df5f846443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91 images belonging to 13 classes.\n",
      "Found 13 images belonging to 13 classes.\n",
      "Found 26 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Generators with Validation Split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.4, 1.6],\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,  # Reduced batch size for memory stability\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f55590-d141-460d-8299-631ef41992c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Enhanced Model Architecture\n",
    "base_model = EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(480, 480, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(13, activation='softmax')  # Ensure this matches your class count\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26883fe-4603-4714-9571-b37549ed6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL BEFORE TRAINING\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c0fbf-7ce0-4f1e-b310-8d64c3f6d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/23 [=================>............] - ETA: 33s - loss: 32.0159 - accuracy: 0.0909  "
     ]
    }
   ],
   "source": [
    "# First Training Phase (Frozen Backbone)\n",
    "history = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a9d91-185e-48d2-b00b-1ad8d4d6a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Snake_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "552cf6f7-de59-4d1f-85c7-a25755412775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/79\n",
      "23/23 [==============================] - 276s 10s/step - loss: 12.2241 - accuracy: 0.8242 - val_loss: 11.4779 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 51/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 12.2709 - accuracy: 0.8242 - val_loss: 11.5094 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 52/79\n",
      "23/23 [==============================] - 231s 10s/step - loss: 12.0690 - accuracy: 0.7802 - val_loss: 11.4916 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 53/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 12.1788 - accuracy: 0.8462 - val_loss: 11.4097 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 54/79\n",
      "23/23 [==============================] - 234s 10s/step - loss: 12.0448 - accuracy: 0.8462 - val_loss: 11.3442 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 55/79\n",
      "23/23 [==============================] - 228s 10s/step - loss: 11.9122 - accuracy: 0.8571 - val_loss: 11.3273 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 56/79\n",
      "23/23 [==============================] - 235s 10s/step - loss: 11.7774 - accuracy: 0.9341 - val_loss: 11.2865 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 57/79\n",
      "23/23 [==============================] - 239s 10s/step - loss: 11.7292 - accuracy: 0.9121 - val_loss: 11.2413 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 58/79\n",
      "23/23 [==============================] - 235s 10s/step - loss: 11.7608 - accuracy: 0.9011 - val_loss: 11.2192 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 59/79\n",
      "23/23 [==============================] - 233s 10s/step - loss: 11.7198 - accuracy: 0.8352 - val_loss: 11.2042 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 60/79\n",
      "23/23 [==============================] - 232s 10s/step - loss: 11.7100 - accuracy: 0.8791 - val_loss: 11.1427 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 61/79\n",
      "23/23 [==============================] - 232s 10s/step - loss: 11.6789 - accuracy: 0.9121 - val_loss: 11.0751 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 62/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 11.7025 - accuracy: 0.8352 - val_loss: 11.0442 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 63/79\n",
      "23/23 [==============================] - 231s 10s/step - loss: 11.4314 - accuracy: 0.9780 - val_loss: 11.0315 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 64/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 11.4620 - accuracy: 0.9121 - val_loss: 11.0312 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 65/79\n",
      "23/23 [==============================] - 229s 10s/step - loss: 11.6722 - accuracy: 0.8132 - val_loss: 10.9752 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 66/79\n",
      "23/23 [==============================] - 231s 10s/step - loss: 11.5966 - accuracy: 0.8352 - val_loss: 10.9030 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 67/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 11.3566 - accuracy: 0.9121 - val_loss: 10.8581 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 68/79\n",
      "23/23 [==============================] - 231s 10s/step - loss: 11.4259 - accuracy: 0.8791 - val_loss: 10.8146 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 69/79\n",
      "23/23 [==============================] - 226s 10s/step - loss: 11.1234 - accuracy: 0.9231 - val_loss: 10.7613 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 70/79\n",
      "23/23 [==============================] - 229s 10s/step - loss: 11.2566 - accuracy: 0.9451 - val_loss: 10.7211 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 71/79\n",
      "23/23 [==============================] - 229s 10s/step - loss: 11.3235 - accuracy: 0.8352 - val_loss: 10.7173 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 72/79\n",
      "23/23 [==============================] - 225s 10s/step - loss: 11.2654 - accuracy: 0.8352 - val_loss: 10.6790 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 73/79\n",
      "23/23 [==============================] - 232s 10s/step - loss: 10.9344 - accuracy: 0.9451 - val_loss: 10.6029 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 74/79\n",
      "23/23 [==============================] - 228s 10s/step - loss: 11.0942 - accuracy: 0.8681 - val_loss: 10.6552 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 75/79\n",
      "23/23 [==============================] - 227s 10s/step - loss: 11.1091 - accuracy: 0.8571 - val_loss: 10.5125 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 76/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 11.0951 - accuracy: 0.9231 - val_loss: 10.4368 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 77/79\n",
      "23/23 [==============================] - 230s 10s/step - loss: 11.0206 - accuracy: 0.9011 - val_loss: 10.3853 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 78/79\n",
      "23/23 [==============================] - 228s 10s/step - loss: 11.0897 - accuracy: 0.8022 - val_loss: 10.3927 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 79/79\n",
      "23/23 [==============================] - 227s 10s/step - loss: 10.8658 - accuracy: 0.9121 - val_loss: 10.3250 - val_accuracy: 1.0000 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Phase\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=history.epoch[-1] + 30,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c11f335-0fe2-4437-9c15-797299913484",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Model_Main/Xception_net_client_bird_cnn.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_bird_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04201eba-d207-44bd-b4d0-5a6cab6e62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-l (Functiona  (None, 15, 15, 1280)     117746848 \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1280)             5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2048)              2623488   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 13)                13325     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,486,957\n",
      "Trainable params: 113,260,957\n",
      "Non-trainable params: 9,226,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to your saved model\n",
    "model_path = 'D:/Model_Main/Xception_net_client_bird_cnn.h5'\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Optional: Print model summary to confirm it's loaded correctly\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa85903-071b-43e6-86a9-d3c364fb82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 33s 3s/step - loss: 10.3675 - accuracy: 1.0000\n",
      "Test Loss: 10.3675 | Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eea63-0eff-4ee3-a7cb-3e9bd60e4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels manually\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "class_labels = {\n",
    "    0: 'Bulbul',\n",
    "    1: 'Cattle',\n",
    "    2: 'Gracula',\n",
    "    3: 'Hawk Owl',\n",
    "    4: 'Magpie Robin',\n",
    "    5: 'Moorhen',\n",
    "    6: 'Parrot',\n",
    "    7: 'Red Dove',\n",
    "    8: 'Serpent Egal',\n",
    "    9: 'Teal',\n",
    "    10: 'Tyto Owl',\n",
    "    11: 'water hen',\n",
    "    12: 'Wood pigeon'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# model = load_model('D:/Model_Main/Xception_net_01.h5')  # Update with your saved model path\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'D:/Test_Val/Client_test/l2.JPG'  # Update with your image path\n",
    "# Load and preprocess the image\n",
    "test_image = load_img(image_path, target_size=(299, 299))  # Corrected function\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0  # Normalize the image\n",
    "\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeeeaffa-ba0e-4b97-9ffe-f0d964c08ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "The predicted class is: Bulbul\n"
     ]
    }
   ],
   "source": [
    "# Define class labels manually\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class_labels = {\n",
    "    0: 'Bulbul',\n",
    "    1: 'Cattle',\n",
    "    2: 'Gracula',\n",
    "    3: 'Hawk Owl',\n",
    "    4: 'Magpie Robin',\n",
    "    5: 'Moorhen',\n",
    "    6: 'Parrot',\n",
    "    7: 'Red Dove',\n",
    "    8: 'Serpent Egal',\n",
    "    9: 'Teal',\n",
    "    10: 'Tyto Owl',\n",
    "    11: 'water hen',\n",
    "    12: 'Wood pigeon'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "# model = load_model('D:/Model_Main/Xception_net_client_bird_cnn.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'D:/Dataset/Birds_CNN/Train/Bulbul/bulbul3.png'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6a8725-49d2-464d-a473-3a719a349130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The predicted class is: Moorhen\n"
     ]
    }
   ],
   "source": [
    "class_labels = {\n",
    "    0: 'Bulbul',\n",
    "    1: 'Cattle',\n",
    "    2: 'Gracula',\n",
    "    3: 'Hawk Owl',\n",
    "    4: 'Magpie Robin',\n",
    "    5: 'Moorhen',\n",
    "    6: 'Parrot',\n",
    "    7: 'Red Dove',\n",
    "    8: 'Serpent Egal',\n",
    "    9: 'Teal',\n",
    "    10: 'Tyto Owl',\n",
    "    11: 'water hen',\n",
    "    12: 'Wood pigeon'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "# model = load_model('D:/Model_Main/Xception_net_client_bird_cnn.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'D:/Bird_cnn_test_out/wh1.jpg'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ee630-1ee6-4edf-b3af-e6770edf4933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
