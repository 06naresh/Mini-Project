{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1438b8ba-0aaa-4dfa-bfd5-4389cdc2f1dd",
   "metadata": {},
   "source": [
    "Frog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207fb217-4c3c-42a7-bc96-3062272587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Optimized Code for Bird Classification\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress AVX warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Mitigate OpenMP conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation with Mixup and CutMix\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, alpha=0.4, cutmix_prob=0.5):\n",
    "        self.generator = generator\n",
    "        self.alpha = alpha\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generator)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, labels = self.generator[index]\n",
    "        \n",
    "        if np.random.rand() < self.cutmix_prob:\n",
    "            return self.cutmix(images, labels)\n",
    "        else:\n",
    "            return self.mixup(images, labels)\n",
    "    \n",
    "    def mixup(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_images = lam * images + (1 - lam) * shuffled_images\n",
    "        mixed_labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def cutmix(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.shape, lam)\n",
    "        images[:, bbx1:bbx2, bby1:bby2, :] = shuffled_images[:, bbx1:bbx2, bby1:bby2, :]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.shape[1] * images.shape[2]))\n",
    "        labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return images, labels\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W = size[1]\n",
    "        H = size[2]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62626bdf-5ebe-45ce-b63a-cba52911878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (UPDATE THESE TO YOUR LOCAL PATHS)\n",
    "train_path = 'D:/Dataset/Frog/train'\n",
    "test_path = 'D:/Dataset/Frog/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a673f3d9-43f8-4f1f-8673-936b5d392d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 8 classes.\n",
      "Found 8 images belonging to 8 classes.\n",
      "Found 16 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Generators with Validation Split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.4, 1.6],\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,  # Reduced batch size for memory stability\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a07d06f-ca78-4b9b-8ca3-f20f13979fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Enhanced Model Architecture\n",
    "base_model = EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(480, 480, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(8, activation='softmax')  # Ensure this matches your class count\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c32a6a-2fbf-4d49-8e09-ad9792074b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL BEFORE TRAINING\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013c590d-7807-4523-8345-ae760c281f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 98s 5s/step - loss: 31.5477 - accuracy: 0.1250 - val_loss: 31.0646 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 58s 4s/step - loss: 31.1322 - accuracy: 0.2321 - val_loss: 30.8323 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 60s 4s/step - loss: 30.5680 - accuracy: 0.3393 - val_loss: 30.5127 - val_accuracy: 0.6250\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 60s 4s/step - loss: 30.1191 - accuracy: 0.4643 - val_loss: 30.2294 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 30.1271 - accuracy: 0.2679 - val_loss: 30.0179 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 67s 5s/step - loss: 29.6828 - accuracy: 0.5000 - val_loss: 29.7162 - val_accuracy: 0.6250\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 66s 5s/step - loss: 29.3823 - accuracy: 0.5893 - val_loss: 29.4359 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 29.1298 - accuracy: 0.5179 - val_loss: 29.1916 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 28.8649 - accuracy: 0.5179 - val_loss: 28.9337 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 65s 5s/step - loss: 28.6969 - accuracy: 0.5357 - val_loss: 28.7610 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 28.5235 - accuracy: 0.5179 - val_loss: 28.3124 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 67s 5s/step - loss: 28.1738 - accuracy: 0.5179 - val_loss: 28.1364 - val_accuracy: 0.6250\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 67s 5s/step - loss: 27.8935 - accuracy: 0.6607 - val_loss: 27.7186 - val_accuracy: 0.8750\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 71s 5s/step - loss: 27.4848 - accuracy: 0.6071 - val_loss: 27.5559 - val_accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 27.4594 - accuracy: 0.5714 - val_loss: 27.2234 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 27.1368 - accuracy: 0.7143 - val_loss: 26.9654 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 26.8907 - accuracy: 0.6429 - val_loss: 26.7639 - val_accuracy: 0.7500\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 26.7776 - accuracy: 0.5893 - val_loss: 26.4135 - val_accuracy: 0.6250\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 26.4155 - accuracy: 0.6964 - val_loss: 26.2189 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 26.0734 - accuracy: 0.6964 - val_loss: 25.9493 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 26.1398 - accuracy: 0.6429 - val_loss: 25.6310 - val_accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 25.7839 - accuracy: 0.5714 - val_loss: 25.5062 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 25.3601 - accuracy: 0.6964 - val_loss: 25.2691 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 25.4648 - accuracy: 0.5357 - val_loss: 24.9816 - val_accuracy: 0.6250\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 24.9335 - accuracy: 0.6607 - val_loss: 24.9039 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 24.9373 - accuracy: 0.5357 - val_loss: 24.5373 - val_accuracy: 0.8750\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 24.5721 - accuracy: 0.6786 - val_loss: 24.3930 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 24.2850 - accuracy: 0.7143 - val_loss: 24.0245 - val_accuracy: 0.6250\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 24.0107 - accuracy: 0.6786 - val_loss: 23.6684 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 23.7387 - accuracy: 0.7679 - val_loss: 23.6080 - val_accuracy: 0.8750\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 23.7676 - accuracy: 0.6429 - val_loss: 23.5080 - val_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 23.5074 - accuracy: 0.6607 - val_loss: 23.1530 - val_accuracy: 0.6250\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 23.2179 - accuracy: 0.6429 - val_loss: 22.8122 - val_accuracy: 0.8750\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 22.8575 - accuracy: 0.7321 - val_loss: 22.3226 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 22.7536 - accuracy: 0.7500 - val_loss: 22.5012 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 22.3304 - accuracy: 0.8036 - val_loss: 22.0005 - val_accuracy: 0.7500\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 22.3321 - accuracy: 0.7143 - val_loss: 21.9470 - val_accuracy: 0.8750\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 22.2336 - accuracy: 0.7857 - val_loss: 21.6466 - val_accuracy: 0.8750\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 21.8169 - accuracy: 0.7500 - val_loss: 21.7241 - val_accuracy: 0.6250\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 21.8952 - accuracy: 0.6964 - val_loss: 21.2411 - val_accuracy: 0.8750\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 21.3080 - accuracy: 0.7143 - val_loss: 20.8855 - val_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 21.3808 - accuracy: 0.6964 - val_loss: 20.7721 - val_accuracy: 0.8750\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 21.1775 - accuracy: 0.6250 - val_loss: 20.5523 - val_accuracy: 0.8750\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 20.7787 - accuracy: 0.7143 - val_loss: 20.3647 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 20.6458 - accuracy: 0.5714 - val_loss: 20.3321 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 20.4394 - accuracy: 0.7321 - val_loss: 20.1530 - val_accuracy: 0.6250\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 20.3609 - accuracy: 0.6250 - val_loss: 19.8239 - val_accuracy: 0.7500\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 20.1082 - accuracy: 0.7143 - val_loss: 19.5192 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 19.7391 - accuracy: 0.8393 - val_loss: 19.3720 - val_accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 19.4268 - accuracy: 0.9464 - val_loss: 19.2412 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# First Training Phase (Frozen Backbone)\n",
    "history = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50021383-16c0-4306-9d7e-58dcbfa11298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Frog_cnn_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62304743-2b04-4ee9-b7f5-526afb52df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/79\n",
      "14/14 [==============================] - 186s 10s/step - loss: 19.5929 - accuracy: 0.6429 - val_loss: 19.1062 - val_accuracy: 0.8750\n",
      "Epoch 51/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 19.7797 - accuracy: 0.5714 - val_loss: 19.4024 - val_accuracy: 0.7500\n",
      "Epoch 52/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 19.5377 - accuracy: 0.7321 - val_loss: 19.1371 - val_accuracy: 0.7500\n",
      "Epoch 53/79\n",
      "14/14 [==============================] - 140s 10s/step - loss: 19.5365 - accuracy: 0.6607 - val_loss: 18.8321 - val_accuracy: 1.0000\n",
      "Epoch 54/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 19.6349 - accuracy: 0.5714 - val_loss: 18.9670 - val_accuracy: 0.7500\n",
      "Epoch 55/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 19.3705 - accuracy: 0.6786 - val_loss: 18.9314 - val_accuracy: 0.8750\n",
      "Epoch 56/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 19.3883 - accuracy: 0.8036 - val_loss: 19.1161 - val_accuracy: 0.6250\n",
      "Epoch 57/79\n",
      "14/14 [==============================] - 140s 10s/step - loss: 19.1922 - accuracy: 0.7857 - val_loss: 19.0492 - val_accuracy: 0.6250\n",
      "Epoch 58/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 19.0627 - accuracy: 0.9107 - val_loss: 18.9739 - val_accuracy: 0.8750\n",
      "Epoch 59/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 19.1872 - accuracy: 0.8036 - val_loss: 18.7512 - val_accuracy: 0.8750\n",
      "Epoch 60/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 19.2030 - accuracy: 0.7143 - val_loss: 18.7907 - val_accuracy: 0.7500\n",
      "Epoch 61/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 19.0448 - accuracy: 0.8929 - val_loss: 18.7728 - val_accuracy: 0.7500\n",
      "Epoch 62/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 19.0629 - accuracy: 0.7679 - val_loss: 18.6826 - val_accuracy: 0.8750\n",
      "Epoch 63/79\n",
      "14/14 [==============================] - 135s 10s/step - loss: 18.9660 - accuracy: 0.8750 - val_loss: 18.7254 - val_accuracy: 0.8750\n",
      "Epoch 64/79\n",
      "14/14 [==============================] - 134s 10s/step - loss: 18.8437 - accuracy: 0.9464 - val_loss: 18.5641 - val_accuracy: 0.8750\n",
      "Epoch 65/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 19.0814 - accuracy: 0.7857 - val_loss: 18.6056 - val_accuracy: 0.8750\n",
      "Epoch 66/79\n",
      "14/14 [==============================] - 138s 10s/step - loss: 19.1217 - accuracy: 0.7321 - val_loss: 18.8214 - val_accuracy: 0.7500\n",
      "Epoch 67/79\n",
      "14/14 [==============================] - 134s 9s/step - loss: 18.9270 - accuracy: 0.7857 - val_loss: 18.5336 - val_accuracy: 0.8750\n",
      "Epoch 68/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 19.1137 - accuracy: 0.7679 - val_loss: 18.7353 - val_accuracy: 0.8750\n",
      "Epoch 69/79\n",
      "14/14 [==============================] - 138s 10s/step - loss: 19.0404 - accuracy: 0.7679 - val_loss: 18.5196 - val_accuracy: 1.0000\n",
      "Epoch 70/79\n",
      "14/14 [==============================] - 134s 10s/step - loss: 19.0405 - accuracy: 0.7679 - val_loss: 18.4341 - val_accuracy: 0.8750\n",
      "Epoch 71/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 18.9697 - accuracy: 0.7500 - val_loss: 18.4758 - val_accuracy: 0.8750\n",
      "Epoch 72/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 18.8769 - accuracy: 0.7321 - val_loss: 18.5099 - val_accuracy: 0.7500\n",
      "Epoch 73/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 18.7728 - accuracy: 0.7857 - val_loss: 18.2031 - val_accuracy: 1.0000\n",
      "Epoch 74/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 18.5718 - accuracy: 0.9107 - val_loss: 18.5631 - val_accuracy: 0.8750\n",
      "Epoch 75/79\n",
      "14/14 [==============================] - 137s 10s/step - loss: 18.6529 - accuracy: 0.8036 - val_loss: 18.3112 - val_accuracy: 0.8750\n",
      "Epoch 76/79\n",
      "14/14 [==============================] - 135s 10s/step - loss: 18.7413 - accuracy: 0.7321 - val_loss: 18.2198 - val_accuracy: 1.0000\n",
      "Epoch 77/79\n",
      "14/14 [==============================] - 139s 10s/step - loss: 18.8100 - accuracy: 0.8036 - val_loss: 18.3219 - val_accuracy: 0.7500\n",
      "Epoch 78/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 18.5863 - accuracy: 0.8393 - val_loss: 18.1567 - val_accuracy: 0.8750\n",
      "Epoch 79/79\n",
      "14/14 [==============================] - 136s 10s/step - loss: 18.5748 - accuracy: 0.9286 - val_loss: 18.4191 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Phase\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=history.epoch[-1] + 30,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abfc2b3-2e5b-41c7-91b9-b518f08aee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Frog_cnn_tunned_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "320a6bad-febb-49e9-8da7-6972ea1b6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step - loss: 21.3749 - accuracy: 0.1250 \n",
      "Test Loss: 21.3749 | Test Accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ce889-186c-4d03-8693-0f384121838b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa87a14-fe24-4bff-ab17-ef4154bfd8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "566f7744-6f6d-4af4-9438-8cef9df43f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad6a8725-49d2-464d-a473-3a719a349130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/Model_Main/Xception_net_client_Frog_cnn_tunned_02.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d187ccf-ac47-4856-9621-436642196a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: 'Bull',\n",
    "    1: 'Charles',\n",
    "    2: 'Shompen',\n",
    "    3: 'Wart',\n",
    "    4: 'Chorus',\n",
    "    5: 'Common',\n",
    "    6: 'Copper',\n",
    "    7: 'Red'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b94d36f-65e2-49ad-8bc6-55b47d4f4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c00ee630-1ee6-4edf-b3af-e6770edf4933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The predicted class is: Wart\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = 'D:/Less_data_test/frog14.jpg'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67068e3d-e457-4637-9302-828c6426ee76",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
