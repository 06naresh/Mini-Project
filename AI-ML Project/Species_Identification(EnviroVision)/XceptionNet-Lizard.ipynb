{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1438b8ba-0aaa-4dfa-bfd5-4389cdc2f1dd",
   "metadata": {},
   "source": [
    "Lizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207fb217-4c3c-42a7-bc96-3062272587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Optimized Code for Bird Classification\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress AVX warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Mitigate OpenMP conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation with Mixup and CutMix\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, alpha=0.4, cutmix_prob=0.5):\n",
    "        self.generator = generator\n",
    "        self.alpha = alpha\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generator)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, labels = self.generator[index]\n",
    "        \n",
    "        if np.random.rand() < self.cutmix_prob:\n",
    "            return self.cutmix(images, labels)\n",
    "        else:\n",
    "            return self.mixup(images, labels)\n",
    "    \n",
    "    def mixup(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_images = lam * images + (1 - lam) * shuffled_images\n",
    "        mixed_labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def cutmix(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.shape, lam)\n",
    "        images[:, bbx1:bbx2, bby1:bby2, :] = shuffled_images[:, bbx1:bbx2, bby1:bby2, :]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.shape[1] * images.shape[2]))\n",
    "        labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return images, labels\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W = size[1]\n",
    "        H = size[2]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62626bdf-5ebe-45ce-b63a-cba52911878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (UPDATE THESE TO YOUR LOCAL PATHS)\n",
    "train_path = 'D:/Dataset/Lizard/train'\n",
    "test_path = 'D:/Dataset/Lizard/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a673f3d9-43f8-4f1f-8673-936b5d392d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 images belonging to 7 classes.\n",
      "Found 7 images belonging to 7 classes.\n",
      "Found 14 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Generators with Validation Split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.4, 1.6],\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,  # Reduced batch size for memory stability\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a07d06f-ca78-4b9b-8ca3-f20f13979fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Enhanced Model Architecture\n",
    "base_model = EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(480, 480, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(7, activation='softmax')  # Ensure this matches your class count\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c32a6a-2fbf-4d49-8e09-ad9792074b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL BEFORE TRAINING\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013c590d-7807-4523-8345-ae760c281f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 82s 4s/step - loss: 31.3769 - accuracy: 0.1020 - val_loss: 30.9270 - val_accuracy: 0.2857\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 44s 3s/step - loss: 30.9127 - accuracy: 0.2245 - val_loss: 30.6543 - val_accuracy: 0.4286\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 45s 3s/step - loss: 30.6035 - accuracy: 0.3265 - val_loss: 30.3896 - val_accuracy: 0.2857\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 30.1589 - accuracy: 0.5102 - val_loss: 30.0307 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 29.8283 - accuracy: 0.4286 - val_loss: 29.7460 - val_accuracy: 0.5714\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 45s 3s/step - loss: 29.6277 - accuracy: 0.5102 - val_loss: 29.6038 - val_accuracy: 0.4286\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 29.4295 - accuracy: 0.5102 - val_loss: 29.2982 - val_accuracy: 0.7143\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 29.1219 - accuracy: 0.4898 - val_loss: 29.0572 - val_accuracy: 0.7143\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 28.9839 - accuracy: 0.4286 - val_loss: 28.8709 - val_accuracy: 0.4286\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 28.8431 - accuracy: 0.4286 - val_loss: 28.7207 - val_accuracy: 0.4286\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 28.2935 - accuracy: 0.6939 - val_loss: 28.4399 - val_accuracy: 0.4286\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 27.9852 - accuracy: 0.7143 - val_loss: 28.1798 - val_accuracy: 0.4286\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 27.7830 - accuracy: 0.6735 - val_loss: 27.9158 - val_accuracy: 0.5714\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 27.5937 - accuracy: 0.6531 - val_loss: 27.6224 - val_accuracy: 0.5714\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 27.4447 - accuracy: 0.5918 - val_loss: 27.4634 - val_accuracy: 0.5714\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 27.1759 - accuracy: 0.6531 - val_loss: 27.0691 - val_accuracy: 0.5714\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 27.0851 - accuracy: 0.5510 - val_loss: 27.0175 - val_accuracy: 0.4286\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 26.6987 - accuracy: 0.6735 - val_loss: 26.5490 - val_accuracy: 0.7143\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 26.3926 - accuracy: 0.6531 - val_loss: 26.4475 - val_accuracy: 0.5714\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 26.2863 - accuracy: 0.6122 - val_loss: 26.3964 - val_accuracy: 0.5714\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 25.9857 - accuracy: 0.6939 - val_loss: 25.7011 - val_accuracy: 0.8571\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 25.8753 - accuracy: 0.6122 - val_loss: 25.6767 - val_accuracy: 0.5714\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 25.6400 - accuracy: 0.5918 - val_loss: 25.2911 - val_accuracy: 0.7143\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 25.3582 - accuracy: 0.6122 - val_loss: 25.2019 - val_accuracy: 0.5714\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 25.1260 - accuracy: 0.6939 - val_loss: 25.1240 - val_accuracy: 0.5714\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 24.9505 - accuracy: 0.6122 - val_loss: 24.7478 - val_accuracy: 0.7143\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 24.7080 - accuracy: 0.7143 - val_loss: 24.7335 - val_accuracy: 0.5714\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 24.5129 - accuracy: 0.6122 - val_loss: 24.3636 - val_accuracy: 0.4286\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 24.3067 - accuracy: 0.6122 - val_loss: 24.4316 - val_accuracy: 0.2857\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 23.8644 - accuracy: 0.7347 - val_loss: 23.9548 - val_accuracy: 0.5714\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 48s 4s/step - loss: 23.7363 - accuracy: 0.7551 - val_loss: 23.8545 - val_accuracy: 0.5714\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 48s 4s/step - loss: 23.6087 - accuracy: 0.6735 - val_loss: 23.7027 - val_accuracy: 0.5714\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 23.4105 - accuracy: 0.7959 - val_loss: 23.4500 - val_accuracy: 0.4286\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 23.2773 - accuracy: 0.7143 - val_loss: 22.8947 - val_accuracy: 0.8571\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 22.9677 - accuracy: 0.7347 - val_loss: 23.0913 - val_accuracy: 0.5714\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 22.8862 - accuracy: 0.7143 - val_loss: 22.8407 - val_accuracy: 0.4286\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 22.4943 - accuracy: 0.8367 - val_loss: 22.5356 - val_accuracy: 0.5714\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 22.5727 - accuracy: 0.5510 - val_loss: 22.4823 - val_accuracy: 0.4286\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 22.0440 - accuracy: 0.7347 - val_loss: 22.1426 - val_accuracy: 0.7143\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 21.8463 - accuracy: 0.6531 - val_loss: 21.8846 - val_accuracy: 0.4286\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 21.5474 - accuracy: 0.8163 - val_loss: 21.9230 - val_accuracy: 0.4286\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 21.3531 - accuracy: 0.7755 - val_loss: 21.8542 - val_accuracy: 0.4286\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 21.2302 - accuracy: 0.7347 - val_loss: 21.5057 - val_accuracy: 0.5714\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 20.8042 - accuracy: 0.8571 - val_loss: 21.2318 - val_accuracy: 0.4286\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 20.7627 - accuracy: 0.7347 - val_loss: 21.2803 - val_accuracy: 0.4286\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 20.6098 - accuracy: 0.7959 - val_loss: 20.5387 - val_accuracy: 0.4286\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 46s 3s/step - loss: 20.4205 - accuracy: 0.7959 - val_loss: 20.8632 - val_accuracy: 0.4286\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 47s 4s/step - loss: 20.3208 - accuracy: 0.7347 - val_loss: 20.7102 - val_accuracy: 0.2857\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 20.1840 - accuracy: 0.6939 - val_loss: 20.2730 - val_accuracy: 0.5714\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 46s 4s/step - loss: 19.8356 - accuracy: 0.7755 - val_loss: 20.1567 - val_accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "# First Training Phase (Frozen Backbone)\n",
    "history = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50021383-16c0-4306-9d7e-58dcbfa11298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Lizard_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62304743-2b04-4ee9-b7f5-526afb52df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/79\n",
      "13/13 [==============================] - 156s 9s/step - loss: 19.9446 - accuracy: 0.5714 - val_loss: 20.3850 - val_accuracy: 0.5714\n",
      "Epoch 51/79\n",
      "13/13 [==============================] - 108s 8s/step - loss: 19.9074 - accuracy: 0.6735 - val_loss: 20.3868 - val_accuracy: 0.5714\n",
      "Epoch 52/79\n",
      "13/13 [==============================] - 109s 8s/step - loss: 19.7374 - accuracy: 0.7551 - val_loss: 20.6610 - val_accuracy: 0.4286\n",
      "Epoch 53/79\n",
      "13/13 [==============================] - 110s 8s/step - loss: 19.6357 - accuracy: 0.7143 - val_loss: 20.1511 - val_accuracy: 0.4286\n",
      "Epoch 54/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.6518 - accuracy: 0.7755 - val_loss: 20.0721 - val_accuracy: 0.1429\n",
      "Epoch 55/79\n",
      "13/13 [==============================] - 116s 9s/step - loss: 19.6034 - accuracy: 0.7551 - val_loss: 20.1560 - val_accuracy: 0.2857\n",
      "Epoch 56/79\n",
      "13/13 [==============================] - 120s 9s/step - loss: 19.7643 - accuracy: 0.6939 - val_loss: 19.4135 - val_accuracy: 0.7143\n",
      "Epoch 57/79\n",
      "13/13 [==============================] - 125s 10s/step - loss: 19.4843 - accuracy: 0.8163 - val_loss: 20.1003 - val_accuracy: 0.4286\n",
      "Epoch 58/79\n",
      "13/13 [==============================] - 117s 10s/step - loss: 19.5399 - accuracy: 0.7959 - val_loss: 20.1660 - val_accuracy: 0.2857\n",
      "Epoch 59/79\n",
      "13/13 [==============================] - 115s 9s/step - loss: 19.5207 - accuracy: 0.7347 - val_loss: 19.7238 - val_accuracy: 0.7143\n",
      "Epoch 60/79\n",
      "13/13 [==============================] - 115s 9s/step - loss: 19.5914 - accuracy: 0.7551 - val_loss: 19.7580 - val_accuracy: 0.4286\n",
      "Epoch 61/79\n",
      "13/13 [==============================] - 116s 9s/step - loss: 19.4750 - accuracy: 0.7755 - val_loss: 20.2032 - val_accuracy: 0.4286\n",
      "Epoch 62/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.4221 - accuracy: 0.7959 - val_loss: 19.3654 - val_accuracy: 0.7143\n",
      "Epoch 63/79\n",
      "13/13 [==============================] - 114s 9s/step - loss: 19.5332 - accuracy: 0.6939 - val_loss: 19.5568 - val_accuracy: 0.5714\n",
      "Epoch 64/79\n",
      "13/13 [==============================] - 114s 9s/step - loss: 19.3909 - accuracy: 0.8367 - val_loss: 19.9120 - val_accuracy: 0.5714\n",
      "Epoch 65/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.1934 - accuracy: 0.8776 - val_loss: 19.6069 - val_accuracy: 0.5714\n",
      "Epoch 66/79\n",
      "13/13 [==============================] - 115s 9s/step - loss: 19.1749 - accuracy: 0.8776 - val_loss: 19.8087 - val_accuracy: 0.5714\n",
      "Epoch 67/79\n",
      "13/13 [==============================] - 116s 9s/step - loss: 19.3731 - accuracy: 0.8163 - val_loss: 19.9315 - val_accuracy: 0.2857\n",
      "Epoch 68/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.3244 - accuracy: 0.8163 - val_loss: 19.9211 - val_accuracy: 0.4286\n",
      "Epoch 69/79\n",
      "13/13 [==============================] - 116s 9s/step - loss: 19.1451 - accuracy: 0.8367 - val_loss: 19.8730 - val_accuracy: 0.5714\n",
      "Epoch 70/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.1511 - accuracy: 0.8367 - val_loss: 19.8565 - val_accuracy: 0.4286\n",
      "Epoch 71/79\n",
      "13/13 [==============================] - 116s 9s/step - loss: 19.2048 - accuracy: 0.7755 - val_loss: 19.8869 - val_accuracy: 0.4286\n",
      "Epoch 72/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.2964 - accuracy: 0.7551 - val_loss: 19.4546 - val_accuracy: 0.5714\n",
      "Epoch 73/79\n",
      "13/13 [==============================] - 113s 9s/step - loss: 19.0607 - accuracy: 0.8571 - val_loss: 19.6053 - val_accuracy: 0.2857\n",
      "Epoch 74/79\n",
      "13/13 [==============================] - 110s 8s/step - loss: 18.8940 - accuracy: 0.8980 - val_loss: 20.1541 - val_accuracy: 0.4286\n",
      "Epoch 75/79\n",
      "13/13 [==============================] - 109s 8s/step - loss: 19.1952 - accuracy: 0.8163 - val_loss: 19.6501 - val_accuracy: 0.5714\n",
      "Epoch 76/79\n",
      "13/13 [==============================] - 108s 8s/step - loss: 19.0130 - accuracy: 0.7551 - val_loss: 19.9288 - val_accuracy: 0.2857\n",
      "Epoch 77/79\n",
      "13/13 [==============================] - 109s 8s/step - loss: 18.9825 - accuracy: 0.8163 - val_loss: 19.9778 - val_accuracy: 0.2857\n",
      "Epoch 78/79\n",
      "13/13 [==============================] - 111s 9s/step - loss: 19.0159 - accuracy: 0.8163 - val_loss: 19.3046 - val_accuracy: 0.4286\n",
      "Epoch 79/79\n",
      "13/13 [==============================] - 110s 8s/step - loss: 18.6811 - accuracy: 0.8980 - val_loss: 19.1411 - val_accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Phase\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=history.epoch[-1] + 30,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abfc2b3-2e5b-41c7-91b9-b518f08aee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Lizard_cnn_tunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "320a6bad-febb-49e9-8da7-6972ea1b6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 10s 2s/step - loss: 19.3474 - accuracy: 0.5714\n",
      "Test Loss: 19.3474 | Test Accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ce889-186c-4d03-8693-0f384121838b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa87a14-fe24-4bff-ab17-ef4154bfd8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f7744-6f6d-4af4-9438-8cef9df43f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eea63-0eff-4ee3-a7cb-3e9bd60e4f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeeeaffa-ba0e-4b97-9ffe-f0d964c08ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc33a3c8-1a4f-45d2-9997-febf21ebe701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/Model_Main/Xception_net_client_Lizard_cnn_tunned.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad6a8725-49d2-464d-a473-3a719a349130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: 'Bent Gecko',\n",
    "    1: 'Blyth Gecko',\n",
    "    2: 'Daneil Lizard',\n",
    "    3: 'Green Crest Lizard',\n",
    "    4: 'Olive tree shink',\n",
    "    5: 'crested bay lizard',\n",
    "    6: 'oriental garden lizard'\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c00ee630-1ee6-4edf-b3af-e6770edf4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np  # Ensure numpy is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad5b36c4-ba0d-4aba-a3f5-6db21f852dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The predicted class is: oriental garden lizard\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = 'D:/Less_data_test/Lizard/l24.jpg'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95140f0c-5145-4ee6-9de6-550ccf29426c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64b231-f713-4183-bf1b-143524999b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
