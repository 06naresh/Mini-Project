{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da40846b-46a6-445f-9e52-11f97f4d1950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5732117-9098-4f57-973d-b59163f22bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths (CHANGE THESE TO YOUR LOCAL FOLDERS)\n",
    "train_path = 'D:/Main_dataset_client/Train'\n",
    "test_path = 'D:/Main_dataset_client/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 images belonging to 7 classes.\n",
      "Found 14 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,           # Increased from 40 to 45 degrees\n",
    "    width_shift_range=0.3,       # Increased from 0.2 to 0.3\n",
    "    height_shift_range=0.3,      # Increased from 0.2 to 0.3\n",
    "    shear_range=0.3,             # Increased from 0.2 to 0.3\n",
    "    zoom_range=0.3,              # Increased from 0.2 to 0.3\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,          # Added vertical flipping\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.5, 1.5], # Expanded brightness range\n",
    "    channel_shift_range=50.0   # Added color channel shifts]    # Added contrast variation\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Test generator remains unchanged (no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c6bf77-7736-4371-a847-0df5f846443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Xception model\n",
    "base_model = Xception(\n",
    "    input_shape=(299, 299, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f55590-d141-460d-8299-631ef41992c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26883fe-4603-4714-9571-b37549ed6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom classifier\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dropout(0.6),\n",
    "    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(training_set.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693c0fbf-7ce0-4f1e-b310-8d64c3f6d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5acc23-0b1e-4661-b95b-0faa136e795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_xception_new.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8737973d-1dfd-427e-b7cf-844155eb4e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 33s 12s/step - loss: 4.9990 - accuracy: 0.2439 - val_loss: 3.9603 - val_accuracy: 0.2143 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 4.9481 - accuracy: 0.1585 - val_loss: 3.8952 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 26s 10s/step - loss: 4.6736 - accuracy: 0.2317 - val_loss: 3.8370 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 4.4459 - accuracy: 0.3171 - val_loss: 3.7795 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 4.0747 - accuracy: 0.3659 - val_loss: 3.7259 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 3.4903 - accuracy: 0.5000 - val_loss: 3.6736 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 26s 8s/step - loss: 3.5096 - accuracy: 0.5122 - val_loss: 3.6220 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 3.4872 - accuracy: 0.5122 - val_loss: 3.5732 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 3.1639 - accuracy: 0.6463 - val_loss: 3.5273 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 3.3755 - accuracy: 0.5366 - val_loss: 3.4840 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 26s 8s/step - loss: 2.8863 - accuracy: 0.6829 - val_loss: 3.4422 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.7687 - accuracy: 0.6829 - val_loss: 3.4015 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.9872 - accuracy: 0.6463 - val_loss: 3.3610 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.9067 - accuracy: 0.7195 - val_loss: 3.3210 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.8859 - accuracy: 0.7317 - val_loss: 3.2815 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.8696 - accuracy: 0.7561 - val_loss: 3.2424 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.7284 - accuracy: 0.7805 - val_loss: 3.2057 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.7362 - accuracy: 0.7561 - val_loss: 3.1698 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.5611 - accuracy: 0.8293 - val_loss: 3.1354 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.6687 - accuracy: 0.7927 - val_loss: 3.1035 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.6393 - accuracy: 0.8171 - val_loss: 3.0734 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.5394 - accuracy: 0.8293 - val_loss: 3.0432 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.4854 - accuracy: 0.8780 - val_loss: 3.0139 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.5808 - accuracy: 0.7683 - val_loss: 2.9850 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 26s 8s/step - loss: 2.4323 - accuracy: 0.8659 - val_loss: 2.9571 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.4430 - accuracy: 0.8415 - val_loss: 2.9294 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.4817 - accuracy: 0.8293 - val_loss: 2.9025 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.4795 - accuracy: 0.8659 - val_loss: 2.8757 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.4091 - accuracy: 0.8780 - val_loss: 2.8496 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.3326 - accuracy: 0.8902 - val_loss: 2.8246 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.4585 - accuracy: 0.8415 - val_loss: 2.8013 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.4947 - accuracy: 0.8780 - val_loss: 2.7778 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.3141 - accuracy: 0.9024 - val_loss: 2.7540 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.3696 - accuracy: 0.8780 - val_loss: 2.7320 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 25s 7s/step - loss: 2.4376 - accuracy: 0.8780 - val_loss: 2.7110 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.3465 - accuracy: 0.8902 - val_loss: 2.6892 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.3862 - accuracy: 0.8902 - val_loss: 2.6679 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.2642 - accuracy: 0.9390 - val_loss: 2.6460 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.2637 - accuracy: 0.9146 - val_loss: 2.6241 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.2455 - accuracy: 0.9390 - val_loss: 2.6041 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 25s 7s/step - loss: 2.2744 - accuracy: 0.8902 - val_loss: 2.5852 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.2566 - accuracy: 0.9512 - val_loss: 2.5675 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.3394 - accuracy: 0.9146 - val_loss: 2.5495 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 26s 8s/step - loss: 2.3797 - accuracy: 0.9024 - val_loss: 2.5325 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 25s 10s/step - loss: 2.2610 - accuracy: 0.9146 - val_loss: 2.5166 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.2539 - accuracy: 0.9146 - val_loss: 2.5000 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 25s 7s/step - loss: 2.2397 - accuracy: 0.9024 - val_loss: 2.4843 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.2240 - accuracy: 0.9268 - val_loss: 2.4688 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.2489 - accuracy: 0.9268 - val_loss: 2.4539 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 25s 8s/step - loss: 2.1940 - accuracy: 0.9512 - val_loss: 2.4397 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa85903-071b-43e6-86a9-d3c364fb82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 2.4397 - accuracy: 1.0000\n",
      "Test Loss: 2.4397 | Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_set)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2cfff45-4afa-4aa7-8040-801944246d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4906b54-b3f7-4f79-8797-e29fbebb6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: Unfreeze some layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8f55ed-589c-4f93-a6f1-05471023fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ab70c7-6e34-45c5-bf56-0b570778d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning training\n",
    "history_fine = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=20,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de019d3d-c937-448f-bcc0-9499dcb539e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 2.4397 - accuracy: 1.0000\n",
      "Test Loss: 2.4397 | Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate after fine-tuning\n",
    "eval_results = model.evaluate(test_set)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df7cd3f6-b155-43b1-8058-8be9fd1a470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_tunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb52ea0e-a7e2-44c7-85d6-36eded4d78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 913ms/step\n",
      "The predicted class is: Frog\n"
     ]
    }
   ],
   "source": [
    "# Define class labels manually\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "class_labels = {\n",
    "    0: 'Birds',\n",
    "    1: 'Butterflies',\n",
    "    2: 'Frog',\n",
    "    3: 'Snakes',\n",
    "    4: 'Odonata',\n",
    "    5: 'Moths',\n",
    "    6: 'Lizard'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = load_model('D:/Model_Main/Xception_net_client.h5')  # Update with your saved model path\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'D:/Less_data_test/c.JPG'  # Update with your image path\n",
    "# Load and preprocess the image\n",
    "test_image = load_img(image_path, target_size=(299, 299))  # Corrected function\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0  # Normalize the image\n",
    "\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eea63-0eff-4ee3-a7cb-3e9bd60e4f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
