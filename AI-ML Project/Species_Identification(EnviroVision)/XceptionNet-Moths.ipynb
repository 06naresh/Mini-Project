{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207fb217-4c3c-42a7-bc96-3062272587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Optimized Code for Bird Classification\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress AVX warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Mitigate OpenMP conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation with Mixup and CutMix\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, alpha=0.4, cutmix_prob=0.5):\n",
    "        self.generator = generator\n",
    "        self.alpha = alpha\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generator)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, labels = self.generator[index]\n",
    "        \n",
    "        if np.random.rand() < self.cutmix_prob:\n",
    "            return self.cutmix(images, labels)\n",
    "        else:\n",
    "            return self.mixup(images, labels)\n",
    "    \n",
    "    def mixup(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_images = lam * images + (1 - lam) * shuffled_images\n",
    "        mixed_labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def cutmix(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.shape, lam)\n",
    "        images[:, bbx1:bbx2, bby1:bby2, :] = shuffled_images[:, bbx1:bbx2, bby1:bby2, :]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.shape[1] * images.shape[2]))\n",
    "        labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return images, labels\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W = size[1]\n",
    "        H = size[2]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462ce40c-e971-4fd7-99a6-ea9174ea6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (UPDATE THESE TO YOUR LOCAL PATHS)\n",
    "train_path = 'D:/Dataset/Moths/Train'\n",
    "test_path = 'D:/Dataset/Moths/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c6bf77-7736-4371-a847-0df5f846443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 16 classes.\n",
      "Found 16 images belonging to 16 classes.\n",
      "Found 32 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Generators with Validation Split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.4, 1.6],\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,  # Reduced batch size for memory stability\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f55590-d141-460d-8299-631ef41992c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Enhanced Model Architecture\n",
    "base_model = EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(480, 480, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(16, activation='softmax')  # Ensure this matches your class count\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26883fe-4603-4714-9571-b37549ed6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL BEFORE TRAINING\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693c0fbf-7ce0-4f1e-b310-8d64c3f6d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 156s 4s/step - loss: 32.2041 - accuracy: 0.0536 - val_loss: 31.5404 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 113s 4s/step - loss: 31.3832 - accuracy: 0.1071 - val_loss: 31.0166 - val_accuracy: 0.5625\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 30.7490 - accuracy: 0.3214 - val_loss: 30.4609 - val_accuracy: 0.6875\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 122s 4s/step - loss: 30.0927 - accuracy: 0.3929 - val_loss: 29.9702 - val_accuracy: 0.5625\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 29.4611 - accuracy: 0.5179 - val_loss: 29.4807 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 29.1900 - accuracy: 0.4375 - val_loss: 28.9337 - val_accuracy: 0.6250\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 122s 4s/step - loss: 28.5620 - accuracy: 0.5625 - val_loss: 28.3599 - val_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 28.1306 - accuracy: 0.5714 - val_loss: 27.8864 - val_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 27.8156 - accuracy: 0.5446 - val_loss: 27.2091 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 27.3272 - accuracy: 0.5893 - val_loss: 26.6773 - val_accuracy: 0.8125\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 26.7702 - accuracy: 0.6696 - val_loss: 26.3366 - val_accuracy: 0.6875\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 119s 4s/step - loss: 26.3046 - accuracy: 0.6786 - val_loss: 25.9229 - val_accuracy: 0.8125\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 25.6779 - accuracy: 0.6875 - val_loss: 25.4338 - val_accuracy: 0.6875\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 25.5296 - accuracy: 0.6339 - val_loss: 24.7812 - val_accuracy: 0.8125\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 116s 4s/step - loss: 24.9567 - accuracy: 0.6696 - val_loss: 24.4287 - val_accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 24.2928 - accuracy: 0.7857 - val_loss: 23.9007 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 24.1638 - accuracy: 0.7232 - val_loss: 23.6538 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 114s 4s/step - loss: 23.7586 - accuracy: 0.6786 - val_loss: 23.1651 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 115s 4s/step - loss: 23.3824 - accuracy: 0.6518 - val_loss: 22.8482 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 22.7085 - accuracy: 0.7857 - val_loss: 22.2825 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 115s 4s/step - loss: 22.4330 - accuracy: 0.7232 - val_loss: 21.9488 - val_accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 114s 4s/step - loss: 22.1084 - accuracy: 0.7054 - val_loss: 21.6225 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 119s 4s/step - loss: 21.6640 - accuracy: 0.7679 - val_loss: 21.2063 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 21.3206 - accuracy: 0.7143 - val_loss: 20.5759 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 20.8639 - accuracy: 0.7321 - val_loss: 20.1454 - val_accuracy: 0.9375\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 20.4430 - accuracy: 0.7768 - val_loss: 20.1986 - val_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 20.0099 - accuracy: 0.8125 - val_loss: 19.6087 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 19.6793 - accuracy: 0.8393 - val_loss: 19.1196 - val_accuracy: 0.8750\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 19.2038 - accuracy: 0.8036 - val_loss: 18.8061 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 117s 4s/step - loss: 19.0684 - accuracy: 0.7143 - val_loss: 18.3188 - val_accuracy: 0.8750\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 116s 4s/step - loss: 18.5659 - accuracy: 0.7500 - val_loss: 18.0095 - val_accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 18.1861 - accuracy: 0.7857 - val_loss: 17.5360 - val_accuracy: 0.9375\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 115s 4s/step - loss: 17.9437 - accuracy: 0.7768 - val_loss: 17.5748 - val_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 115s 4s/step - loss: 17.6584 - accuracy: 0.7411 - val_loss: 17.2578 - val_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 119s 4s/step - loss: 17.1846 - accuracy: 0.8304 - val_loss: 16.6920 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 118s 4s/step - loss: 16.5867 - accuracy: 0.8839 - val_loss: 16.3827 - val_accuracy: 0.8125\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 116s 4s/step - loss: 16.6627 - accuracy: 0.7054 - val_loss: 16.1787 - val_accuracy: 0.6875\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 112s 4s/step - loss: 16.2439 - accuracy: 0.8036 - val_loss: 16.0111 - val_accuracy: 0.6875\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 114s 4s/step - loss: 15.8504 - accuracy: 0.8214 - val_loss: 15.4707 - val_accuracy: 0.7500\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 114s 4s/step - loss: 15.5143 - accuracy: 0.8571 - val_loss: 15.1771 - val_accuracy: 0.6875\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 113s 4s/step - loss: 15.0422 - accuracy: 0.8125 - val_loss: 15.0107 - val_accuracy: 0.6875\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 113s 4s/step - loss: 14.8942 - accuracy: 0.8482 - val_loss: 14.4919 - val_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 114s 4s/step - loss: 14.7165 - accuracy: 0.7857 - val_loss: 14.1724 - val_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 113s 4s/step - loss: 14.4377 - accuracy: 0.7500 - val_loss: 14.1300 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 112s 4s/step - loss: 14.1475 - accuracy: 0.7768 - val_loss: 13.7310 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 112s 4s/step - loss: 13.5085 - accuracy: 0.8661 - val_loss: 13.2139 - val_accuracy: 0.9375\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 111s 4s/step - loss: 13.3538 - accuracy: 0.8125 - val_loss: 13.3247 - val_accuracy: 0.6875\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 110s 4s/step - loss: 13.2447 - accuracy: 0.8125 - val_loss: 12.7135 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 109s 4s/step - loss: 12.9138 - accuracy: 0.8661 - val_loss: 12.4755 - val_accuracy: 0.8125\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 111s 4s/step - loss: 12.6476 - accuracy: 0.8482 - val_loss: 12.2248 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# First Training Phase (Frozen Backbone)\n",
    "history = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ebe71c-3bd5-4201-a737-f083f655ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_moths_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552cf6f7-de59-4d1f-85c7-a25755412775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/79\n",
      "28/28 [==============================] - 327s 9s/step - loss: 12.7522 - accuracy: 0.7321 - val_loss: 12.1176 - val_accuracy: 0.9375\n",
      "Epoch 51/79\n",
      "28/28 [==============================] - 270s 10s/step - loss: 12.5622 - accuracy: 0.8036 - val_loss: 12.2485 - val_accuracy: 0.8125\n",
      "Epoch 52/79\n",
      "28/28 [==============================] - 262s 9s/step - loss: 12.4437 - accuracy: 0.8661 - val_loss: 12.0510 - val_accuracy: 0.7500\n",
      "Epoch 53/79\n",
      "28/28 [==============================] - 286s 10s/step - loss: 12.4878 - accuracy: 0.8036 - val_loss: 12.0078 - val_accuracy: 0.8125\n",
      "Epoch 54/79\n",
      "28/28 [==============================] - 263s 9s/step - loss: 12.4617 - accuracy: 0.8214 - val_loss: 12.2306 - val_accuracy: 0.8125\n",
      "Epoch 55/79\n",
      "28/28 [==============================] - 270s 10s/step - loss: 12.3425 - accuracy: 0.8661 - val_loss: 12.0805 - val_accuracy: 0.6875\n",
      "Epoch 56/79\n",
      "28/28 [==============================] - 258s 9s/step - loss: 12.1134 - accuracy: 0.8929 - val_loss: 11.7875 - val_accuracy: 0.8750\n",
      "Epoch 57/79\n",
      "28/28 [==============================] - 270s 10s/step - loss: 12.2558 - accuracy: 0.8750 - val_loss: 11.9400 - val_accuracy: 0.8125\n",
      "Epoch 58/79\n",
      "28/28 [==============================] - 284s 10s/step - loss: 12.3421 - accuracy: 0.8393 - val_loss: 11.7256 - val_accuracy: 0.8750\n",
      "Epoch 59/79\n",
      "28/28 [==============================] - 282s 10s/step - loss: 12.2541 - accuracy: 0.8482 - val_loss: 11.6235 - val_accuracy: 0.8750\n",
      "Epoch 60/79\n",
      "28/28 [==============================] - 270s 10s/step - loss: 12.0973 - accuracy: 0.8304 - val_loss: 11.5898 - val_accuracy: 0.9375\n",
      "Epoch 61/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 12.2350 - accuracy: 0.8304 - val_loss: 11.6519 - val_accuracy: 0.8125\n",
      "Epoch 62/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 12.0968 - accuracy: 0.8482 - val_loss: 11.4336 - val_accuracy: 0.9375\n",
      "Epoch 63/79\n",
      "28/28 [==============================] - 272s 10s/step - loss: 12.1179 - accuracy: 0.8750 - val_loss: 11.5853 - val_accuracy: 0.8750\n",
      "Epoch 64/79\n",
      "28/28 [==============================] - 272s 10s/step - loss: 12.0423 - accuracy: 0.7857 - val_loss: 11.5066 - val_accuracy: 0.8125\n",
      "Epoch 65/79\n",
      "28/28 [==============================] - 273s 10s/step - loss: 11.9649 - accuracy: 0.8839 - val_loss: 11.5431 - val_accuracy: 0.8750\n",
      "Epoch 66/79\n",
      "28/28 [==============================] - 275s 10s/step - loss: 11.8075 - accuracy: 0.8571 - val_loss: 11.3336 - val_accuracy: 0.8750\n",
      "Epoch 67/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 11.8480 - accuracy: 0.8661 - val_loss: 11.4093 - val_accuracy: 0.8750\n",
      "Epoch 68/79\n",
      "28/28 [==============================] - 274s 10s/step - loss: 11.8256 - accuracy: 0.8661 - val_loss: 11.2611 - val_accuracy: 0.9375\n",
      "Epoch 69/79\n",
      "28/28 [==============================] - 270s 10s/step - loss: 11.6803 - accuracy: 0.8482 - val_loss: 11.2241 - val_accuracy: 1.0000\n",
      "Epoch 70/79\n",
      "28/28 [==============================] - 275s 10s/step - loss: 11.6938 - accuracy: 0.8482 - val_loss: 11.1814 - val_accuracy: 0.8750\n",
      "Epoch 71/79\n",
      "28/28 [==============================] - 274s 10s/step - loss: 11.6434 - accuracy: 0.8393 - val_loss: 11.1365 - val_accuracy: 0.8750\n",
      "Epoch 72/79\n",
      "28/28 [==============================] - 273s 10s/step - loss: 11.3296 - accuracy: 0.9554 - val_loss: 11.1461 - val_accuracy: 0.8750\n",
      "Epoch 73/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 11.3985 - accuracy: 0.8750 - val_loss: 10.9757 - val_accuracy: 0.9375\n",
      "Epoch 74/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 11.3717 - accuracy: 0.9464 - val_loss: 10.9900 - val_accuracy: 0.8750\n",
      "Epoch 75/79\n",
      "28/28 [==============================] - 274s 10s/step - loss: 11.4786 - accuracy: 0.8661 - val_loss: 11.0687 - val_accuracy: 0.8125\n",
      "Epoch 76/79\n",
      "28/28 [==============================] - 273s 10s/step - loss: 11.3522 - accuracy: 0.9107 - val_loss: 11.0418 - val_accuracy: 0.8750\n",
      "Epoch 77/79\n",
      "28/28 [==============================] - 271s 10s/step - loss: 11.1924 - accuracy: 0.9286 - val_loss: 10.8838 - val_accuracy: 0.9375\n",
      "Epoch 78/79\n",
      "28/28 [==============================] - 272s 10s/step - loss: 11.4349 - accuracy: 0.8125 - val_loss: 10.7607 - val_accuracy: 0.9375\n",
      "Epoch 79/79\n",
      "28/28 [==============================] - 272s 10s/step - loss: 11.2468 - accuracy: 0.8750 - val_loss: 10.8312 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Phase\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=history.epoch[-1] + 30,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c11f335-0fe2-4437-9c15-797299913484",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.38 MiB for an array with shape (1, 1, 384, 2304) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/Model_Main/Xception_net_client_moths_cnn_tunned.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\evenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\evenv\\lib\\site-packages\\keras\\backend.py:3968\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3956\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   3957\u001b[0m \n\u001b[0;32m   3958\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   3966\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3968\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3970\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.38 MiB for an array with shape (1, 1, 384, 2304) and data type float32"
     ]
    }
   ],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_moths_cnn_tunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0879f1-cc19-4b22-9d8f-9c36d1ae8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 25s 3s/step - loss: 10.6721 - accuracy: 1.0000\n",
      "Test Loss: 10.6721 | Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1438b8ba-0aaa-4dfa-bfd5-4389cdc2f1dd",
   "metadata": {},
   "source": [
    "moths test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123ce889-186c-4d03-8693-0f384121838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa87a14-fe24-4bff-ab17-ef4154bfd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/Model_Main/Xception_net_client_moths_cnn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "566f7744-6f6d-4af4-9438-8cef9df43f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: 'Agrioglypta',\n",
    "    1: 'Antitrygodes',\n",
    "    2: 'Arthroschista',\n",
    "    3: 'Eudocima',\n",
    "    4: 'Glyphodes',\n",
    "    5: 'Greater Hawkmoth',\n",
    "    6: 'Lyssa zampa',\n",
    "    7: 'Nevrina',\n",
    "    8: 'Omiodes',\n",
    "    9: 'Pingasa',\n",
    "    10: 'Syllepte',\n",
    "    11: 'Tiger Moth',\n",
    "    12: 'Trigonodes',\n",
    "    13: 'Urapteroides',\n",
    "    14: 'crameri',\n",
    "    15: 'rutilalis'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04201eba-d207-44bd-b4d0-5a6cab6e62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "afa85903-071b-43e6-86a9-d3c364fb82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The predicted class is: Urapteroides\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = 'D:/Less_data_test/moths/m65.jpg'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8722751-ac36-415b-b05f-d6f292db3131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8680f1a-cca6-4e57-a45c-6064a63a74c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
