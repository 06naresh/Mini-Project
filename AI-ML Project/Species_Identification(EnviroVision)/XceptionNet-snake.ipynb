{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207fb217-4c3c-42a7-bc96-3062272587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Optimized Code for Bird Classification\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress AVX warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Mitigate OpenMP conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084d451d-29b0-4108-950e-e9b3cb2c6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01189549-07a3-4030-84b5-8e068d6508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation with Mixup and CutMix\n",
    "class AugmentedGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, generator, alpha=0.4, cutmix_prob=0.5):\n",
    "        self.generator = generator\n",
    "        self.alpha = alpha\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generator)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, labels = self.generator[index]\n",
    "        \n",
    "        if np.random.rand() < self.cutmix_prob:\n",
    "            return self.cutmix(images, labels)\n",
    "        else:\n",
    "            return self.mixup(images, labels)\n",
    "    \n",
    "    def mixup(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        mixed_images = lam * images + (1 - lam) * shuffled_images\n",
    "        mixed_labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    def cutmix(self, images, labels):\n",
    "        indices = np.random.permutation(images.shape[0])\n",
    "        shuffled_images = images[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.shape, lam)\n",
    "        images[:, bbx1:bbx2, bby1:bby2, :] = shuffled_images[:, bbx1:bbx2, bby1:bby2, :]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.shape[1] * images.shape[2]))\n",
    "        labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "        return images, labels\n",
    "\n",
    "    def rand_bbox(self, size, lam):\n",
    "        W = size[1]\n",
    "        H = size[2]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462ce40c-e971-4fd7-99a6-ea9174ea6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (UPDATE THESE TO YOUR LOCAL PATHS)\n",
    "train_path = 'D:/Dataset/Snakes/Train'\n",
    "test_path = 'D:/Dataset/Snakes/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c6bf77-7736-4371-a847-0df5f846443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 images belonging to 9 classes.\n",
      "Found 9 images belonging to 9 classes.\n",
      "Found 18 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Generators with Validation Split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    rotation_range=60,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.4, 1.6],\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,  # Reduced batch size for memory stability\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=4,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f55590-d141-460d-8299-631ef41992c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Enhanced Model Architecture\n",
    "base_model = EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(480, 480, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    BatchNormalization(),\n",
    "    Dense(2048, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='swish', kernel_regularizer='l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(9, activation='softmax')  # Ensure this matches your class count\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26883fe-4603-4714-9571-b37549ed6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE THE MODEL BEFORE TRAINING\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693c0fbf-7ce0-4f1e-b310-8d64c3f6d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 101s 4s/step - loss: 31.6307 - accuracy: 0.1587 - val_loss: 31.1202 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 63s 4s/step - loss: 30.7728 - accuracy: 0.3651 - val_loss: 30.7201 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 64s 4s/step - loss: 30.1890 - accuracy: 0.6190 - val_loss: 30.3529 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 66s 4s/step - loss: 29.8643 - accuracy: 0.5556 - val_loss: 29.9499 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 67s 4s/step - loss: 29.6425 - accuracy: 0.5714 - val_loss: 29.6639 - val_accuracy: 0.5556\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 67s 4s/step - loss: 29.3254 - accuracy: 0.6190 - val_loss: 29.3155 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 66s 4s/step - loss: 28.7950 - accuracy: 0.6190 - val_loss: 28.9628 - val_accuracy: 0.8889\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 67s 4s/step - loss: 28.7328 - accuracy: 0.5714 - val_loss: 28.7110 - val_accuracy: 0.7778\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 28.1204 - accuracy: 0.7778 - val_loss: 28.3450 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 28.1079 - accuracy: 0.5873 - val_loss: 28.0228 - val_accuracy: 0.6667\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 27.6496 - accuracy: 0.6825 - val_loss: 27.5580 - val_accuracy: 0.7778\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 27.4477 - accuracy: 0.7619 - val_loss: 27.2741 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 27.0398 - accuracy: 0.7619 - val_loss: 26.9243 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 26.5973 - accuracy: 0.7937 - val_loss: 26.5775 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 26.2112 - accuracy: 0.8254 - val_loss: 26.1362 - val_accuracy: 0.7778\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 26.0709 - accuracy: 0.7302 - val_loss: 25.8474 - val_accuracy: 0.7778\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 25.6459 - accuracy: 0.7619 - val_loss: 25.5845 - val_accuracy: 0.7778\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 25.5205 - accuracy: 0.7143 - val_loss: 25.0898 - val_accuracy: 0.7778\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 25.0990 - accuracy: 0.8730 - val_loss: 24.9760 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 24.9211 - accuracy: 0.7143 - val_loss: 24.4889 - val_accuracy: 0.8889\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 24.5917 - accuracy: 0.7619 - val_loss: 24.1877 - val_accuracy: 0.7778\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 24.3488 - accuracy: 0.6825 - val_loss: 23.7603 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 23.7808 - accuracy: 0.8889 - val_loss: 23.3864 - val_accuracy: 0.8889\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 23.6673 - accuracy: 0.7302 - val_loss: 23.1233 - val_accuracy: 0.8889\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 23.3441 - accuracy: 0.7619 - val_loss: 22.8536 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 23.3172 - accuracy: 0.6825 - val_loss: 22.6239 - val_accuracy: 0.7778\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 22.5737 - accuracy: 0.9206 - val_loss: 22.1721 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 71s 4s/step - loss: 22.5221 - accuracy: 0.8095 - val_loss: 21.8988 - val_accuracy: 0.7778\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 22.1582 - accuracy: 0.7937 - val_loss: 21.6198 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 22.2306 - accuracy: 0.6825 - val_loss: 21.4651 - val_accuracy: 0.8889\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 21.4677 - accuracy: 0.8254 - val_loss: 21.2090 - val_accuracy: 0.8889\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 21.3170 - accuracy: 0.7143 - val_loss: 20.7954 - val_accuracy: 0.7778\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 21.0093 - accuracy: 0.7460 - val_loss: 20.6711 - val_accuracy: 0.8889\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 20.8374 - accuracy: 0.7302 - val_loss: 20.3615 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 20.5982 - accuracy: 0.7778 - val_loss: 20.0849 - val_accuracy: 0.7778\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 20.2724 - accuracy: 0.7778 - val_loss: 19.8790 - val_accuracy: 0.8889\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 19.9779 - accuracy: 0.7619 - val_loss: 19.5483 - val_accuracy: 0.7778\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 19.4364 - accuracy: 0.9524 - val_loss: 19.3102 - val_accuracy: 0.7778\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 19.4394 - accuracy: 0.8254 - val_loss: 19.0897 - val_accuracy: 0.8889\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 19.1622 - accuracy: 0.9048 - val_loss: 18.6402 - val_accuracy: 0.8889\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 18.8970 - accuracy: 0.8254 - val_loss: 18.5198 - val_accuracy: 0.7778\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 70s 4s/step - loss: 18.6241 - accuracy: 0.8889 - val_loss: 18.0999 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 18.2149 - accuracy: 0.9524 - val_loss: 17.8864 - val_accuracy: 0.8889\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 18.0309 - accuracy: 0.8889 - val_loss: 17.6350 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 17.8843 - accuracy: 0.7619 - val_loss: 17.4872 - val_accuracy: 0.7778\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 17.5037 - accuracy: 0.8730 - val_loss: 17.5257 - val_accuracy: 0.7778\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 69s 4s/step - loss: 17.3044 - accuracy: 0.8730 - val_loss: 16.9214 - val_accuracy: 0.8889\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 17.1554 - accuracy: 0.8413 - val_loss: 16.6500 - val_accuracy: 0.7778\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 16.7809 - accuracy: 0.8730 - val_loss: 16.3576 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 68s 4s/step - loss: 16.6411 - accuracy: 0.9048 - val_loss: 16.2283 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# First Training Phase (Frozen Backbone)\n",
    "history = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ebe71c-3bd5-4201-a737-f083f655ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_Snake_cnn2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552cf6f7-de59-4d1f-85c7-a25755412775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/79\n",
      "16/16 [==============================] - 197s 10s/step - loss: 16.9401 - accuracy: 0.6190 - val_loss: 16.5371 - val_accuracy: 0.7778\n",
      "Epoch 51/79\n",
      "16/16 [==============================] - 150s 9s/step - loss: 16.8172 - accuracy: 0.6825 - val_loss: 16.2112 - val_accuracy: 0.8889\n",
      "Epoch 52/79\n",
      "16/16 [==============================] - 159s 10s/step - loss: 16.6971 - accuracy: 0.7143 - val_loss: 16.2254 - val_accuracy: 0.7778\n",
      "Epoch 53/79\n",
      "16/16 [==============================] - 157s 10s/step - loss: 16.3767 - accuracy: 0.8571 - val_loss: 16.3221 - val_accuracy: 0.7778\n",
      "Epoch 54/79\n",
      "16/16 [==============================] - 155s 10s/step - loss: 16.3987 - accuracy: 0.7778 - val_loss: 16.0024 - val_accuracy: 0.8889\n",
      "Epoch 55/79\n",
      "16/16 [==============================] - 153s 10s/step - loss: 16.5968 - accuracy: 0.7937 - val_loss: 16.1420 - val_accuracy: 0.8889\n",
      "Epoch 56/79\n",
      "16/16 [==============================] - 155s 10s/step - loss: 16.4880 - accuracy: 0.7937 - val_loss: 16.2015 - val_accuracy: 0.7778\n",
      "Epoch 57/79\n",
      "16/16 [==============================] - 154s 10s/step - loss: 16.4498 - accuracy: 0.8254 - val_loss: 15.9983 - val_accuracy: 0.8889\n",
      "Epoch 58/79\n",
      "16/16 [==============================] - 151s 9s/step - loss: 16.3850 - accuracy: 0.8095 - val_loss: 15.8931 - val_accuracy: 0.8889\n",
      "Epoch 59/79\n",
      "16/16 [==============================] - 154s 10s/step - loss: 16.4144 - accuracy: 0.7778 - val_loss: 15.9936 - val_accuracy: 0.8889\n",
      "Epoch 60/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 16.3921 - accuracy: 0.8413 - val_loss: 16.1378 - val_accuracy: 0.7778\n",
      "Epoch 61/79\n",
      "16/16 [==============================] - 153s 10s/step - loss: 16.4013 - accuracy: 0.8095 - val_loss: 15.9421 - val_accuracy: 0.8889\n",
      "Epoch 62/79\n",
      "16/16 [==============================] - 151s 9s/step - loss: 16.2004 - accuracy: 0.8730 - val_loss: 15.7416 - val_accuracy: 0.8889\n",
      "Epoch 63/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 16.1760 - accuracy: 0.8413 - val_loss: 15.8790 - val_accuracy: 0.7778\n",
      "Epoch 64/79\n",
      "16/16 [==============================] - 157s 10s/step - loss: 16.0343 - accuracy: 0.9048 - val_loss: 15.9986 - val_accuracy: 0.8889\n",
      "Epoch 65/79\n",
      "16/16 [==============================] - 158s 10s/step - loss: 16.0621 - accuracy: 0.9048 - val_loss: 15.7186 - val_accuracy: 0.8889\n",
      "Epoch 66/79\n",
      "16/16 [==============================] - 157s 10s/step - loss: 16.0804 - accuracy: 0.9206 - val_loss: 15.7510 - val_accuracy: 1.0000\n",
      "Epoch 67/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 16.0823 - accuracy: 0.8730 - val_loss: 15.7282 - val_accuracy: 0.8889\n",
      "Epoch 68/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 15.9136 - accuracy: 0.8254 - val_loss: 15.5943 - val_accuracy: 0.8889\n",
      "Epoch 69/79\n",
      "16/16 [==============================] - 155s 10s/step - loss: 16.0301 - accuracy: 0.7143 - val_loss: 15.6465 - val_accuracy: 1.0000\n",
      "Epoch 70/79\n",
      "16/16 [==============================] - 157s 10s/step - loss: 15.8196 - accuracy: 0.9365 - val_loss: 15.6785 - val_accuracy: 0.8889\n",
      "Epoch 71/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 15.8023 - accuracy: 0.9206 - val_loss: 15.4083 - val_accuracy: 1.0000\n",
      "Epoch 72/79\n",
      "16/16 [==============================] - 157s 10s/step - loss: 15.8467 - accuracy: 0.8889 - val_loss: 15.4969 - val_accuracy: 0.8889\n",
      "Epoch 73/79\n",
      "16/16 [==============================] - 153s 10s/step - loss: 15.6358 - accuracy: 0.9683 - val_loss: 15.5721 - val_accuracy: 0.7778\n",
      "Epoch 74/79\n",
      "16/16 [==============================] - 159s 10s/step - loss: 15.6084 - accuracy: 0.9048 - val_loss: 15.5043 - val_accuracy: 0.8889\n",
      "Epoch 75/79\n",
      "16/16 [==============================] - 162s 10s/step - loss: 15.7645 - accuracy: 0.9048 - val_loss: 15.2547 - val_accuracy: 1.0000\n",
      "Epoch 76/79\n",
      "16/16 [==============================] - 158s 10s/step - loss: 15.7984 - accuracy: 0.8254 - val_loss: 15.2018 - val_accuracy: 1.0000\n",
      "Epoch 77/79\n",
      "16/16 [==============================] - 156s 10s/step - loss: 15.6838 - accuracy: 0.8095 - val_loss: 15.1868 - val_accuracy: 1.0000\n",
      "Epoch 78/79\n",
      "16/16 [==============================] - 159s 10s/step - loss: 15.7920 - accuracy: 0.8730 - val_loss: 15.2909 - val_accuracy: 0.7778\n",
      "Epoch 79/79\n",
      "16/16 [==============================] - 159s 10s/step - loss: 15.6302 - accuracy: 0.9206 - val_loss: 15.4187 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Phase\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    AugmentedGenerator(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=history.epoch[-1] + 30,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c11f335-0fe2-4437-9c15-797299913484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Model_Main/Xception_net_client_snake_cnn_tunned2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04201eba-d207-44bd-b4d0-5a6cab6e62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-l (Functiona  (None, 15, 15, 1280)     117746848 \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1280)             5120      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              2623488   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 9225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,482,857\n",
      "Trainable params: 113,256,857\n",
      "Non-trainable params: 9,226,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to your saved model\n",
    "model_path = 'D:/Model_Main/Xception_net_client_Snake_cnn2.h5'\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Optional: Print model summary to confirm it's loaded correctly\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa85903-071b-43e6-86a9-d3c364fb82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 21s 3s/step - loss: 16.1888 - accuracy: 0.8889\n",
      "Test Loss: 16.1888 | Test Accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {eval_results[0]:.4f} | Test Accuracy: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeeeaffa-ba0e-4b97-9ffe-f0d964c08ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels manually\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class_labels = {\n",
    "    0: 'Bronzeback',\n",
    "    1: 'Cat Snake',\n",
    "    2: 'Central Pit viper',\n",
    "    3: 'Kukri',\n",
    "    4: 'Pit Viper',\n",
    "    5: 'Plumbea',\n",
    "    6: 'Red tail',\n",
    "    7: 'Reticulated python',\n",
    "    8: 'tytleri'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/Model_Main/Xception_net_client_snake_cnn_tunned2.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc33a3c8-1a4f-45d2-9997-febf21ebe701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "The predicted class is: tytleri\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = 'D:/Less_data_test/snake/s25.png'\n",
    "test_image = load_img(image_path, target_size=(480, 480))  # Match model input size\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = preprocess_input(test_image)  # Use EfficientNetV2 preprocessing\n",
    "\n",
    "# Predict the class\n",
    "result = model.predict(test_image)\n",
    "predicted_class = np.argmax(result)\n",
    "\n",
    "# Get the predicted label\n",
    "prediction = class_labels[predicted_class]\n",
    "\n",
    "print(f'The predicted class is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ee630-1ee6-4edf-b3af-e6770edf4933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
